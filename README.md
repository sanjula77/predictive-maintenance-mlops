# Predictive Maintenance MLOps

[![CI - Lint & Test](https://github.com/yourusername/predictive-maintenance-mlops/workflows/CI%20-%20Lint%20%26%20Test/badge.svg)](https://github.com/yourusername/predictive-maintenance-mlops/actions/workflows/ci.yml)
[![Build Docker Image](https://github.com/yourusername/predictive-maintenance-mlops/workflows/Build%20Docker%20Image/badge.svg)](https://github.com/yourusername/predictive-maintenance-mlops/actions/workflows/docker-build.yml)
[![Test API](https://github.com/yourusername/predictive-maintenance-mlops/workflows/Test%20API/badge.svg)](https://github.com/yourusername/predictive-maintenance-mlops/actions/workflows/test-api.yml)
[![Security Checks](https://github.com/yourusername/predictive-maintenance-mlops/workflows/Security%20Checks/badge.svg)](https://github.com/yourusername/predictive-maintenance-mlops/actions/workflows/security.yml)

> **Note**: Replace `yourusername` in the badge URLs with your actual GitHub username/organization.

A production-ready MLOps pipeline for predictive maintenance using Remaining Useful Life (RUL) prediction on CMAPSS aircraft engine data.

## ğŸš€ Features

- **Multiple Model Architectures**: LSTM, BiLSTM, GRU, and Transformer models
- **MLflow Integration**: Complete experiment tracking and model registry
- **Model Versioning**: Automatic version management with metadata tracking
- **Production-Ready API**: FastAPI-based REST API with Docker support
- **Auto-Promotion**: Automatically promotes best model to Production
- **Comprehensive Evaluation**: Built-in model comparison and metrics
- **Docker Support**: Fully containerized for easy deployment

## ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Training Models](#training-models)
- [API Inference Service](#api-inference-service)
- [Docker Deployment](#docker-deployment)
- [Documentation](#documentation)
- [Model Architectures](#model-architectures)
- [Contributing](#contributing)
- [License](#license)

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.10+
- pip
- (Optional) CUDA-capable GPU for faster training
- (Optional) Docker for containerized deployment

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd predictive-maintenance-mlops
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ“Š Quick Start

### 1. Train Models with MLflow (Recommended)

```bash
# Train all models and auto-promote best to Production
python -m src.train_with_mlflow --epochs 20 --auto-promote
```

This will:
- Train all 4 model architectures
- Track experiments in MLflow
- Register all models
- Compare and promote best model automatically

### 2. Start API Server

```bash
# With MLflow (uses Production model)
USE_MLFLOW=true uvicorn src.api.main:app --reload

# Or with Docker
docker-compose up -d
```

### 3. Make Predictions

```bash
# Test API
curl http://localhost:8000/health

# Make prediction
curl -X POST "http://localhost:8000/predict/simple" \
  -H "Content-Type: application/json" \
  -d @example_request.json
```

### 4. View MLflow UI

```bash
mlflow ui
# Open http://localhost:5000
```

## ğŸ“ Project Structure

```
predictive-maintenance-mlops/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ api/               # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py        # API endpoints
â”‚   â”‚   â””â”€â”€ schemas.py     # Pydantic schemas
â”‚   â”œâ”€â”€ data/              # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/            # Model architectures
â”‚   â”œâ”€â”€ train.py           # Basic training script
â”‚   â”œâ”€â”€ train_with_versioning.py  # Training with versioning
â”‚   â”œâ”€â”€ train_with_mlflow.py      # MLflow training (recommended)
â”‚   â”œâ”€â”€ evaluate.py        # Evaluation script
â”‚   â”œâ”€â”€ predict.py         # Prediction script
â”‚   â”œâ”€â”€ model_registry.py  # Legacy model versioning
â”‚   â””â”€â”€ mlflow_utils.py    # MLflow integration utilities
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ API.md            # API documentation
â”‚   â”œâ”€â”€ TRAINING.md       # Training guide
â”‚   â”œâ”€â”€ MLFLOW_GUIDE.md   # MLflow integration
â”‚   â”œâ”€â”€ DOCKER.md         # Docker deployment
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker/                # Docker helper scripts
â”œâ”€â”€ data/                  # Data directory
â”‚   â”œâ”€â”€ raw/              # Raw data files
â”‚   â””â”€â”€ processed/        # Processed data
â”œâ”€â”€ models/               # Trained models (legacy registry)
â”œâ”€â”€ mlruns/               # MLflow tracking data
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ Dockerfile            # Docker image definition
â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ¯ Training Models

### Training Options

**Option 1: MLflow Training (Recommended for Production)**
```bash
python -m src.train_with_mlflow --epochs 20 --auto-promote
```

**Option 2: Training with Versioning**
```bash
python -m src.train_with_versioning --model lstm --epochs 20
```

**Option 3: Basic Training**
```bash
python -m src.train --model lstm --epochs 20
```

### Available Models

- `lstm` - Standard LSTM
- `bilstm` - Bidirectional LSTM
- `gru` - GRU (recommended for speed)
- `transformer` - Transformer encoder

See [Training Guide](docs/TRAINING.md) for detailed information.

## ğŸŒ API Inference Service

### Quick Start

```bash
# Start API server
uvicorn src.api.main:app --reload

# Or using Docker
docker-compose up -d
```

### API Endpoints

- **Health Check**: `GET /` or `GET /health`
- **List Models**: `GET /models`
- **Model Info**: `GET /models/{version}`
- **Predict RUL**: `POST /predict` or `POST /predict/simple`

### Interactive Documentation

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Example Request

```bash
curl -X POST "http://localhost:8000/predict/simple" \
  -H "Content-Type: application/json" \
  -d @example_request.json
```

See [API Documentation](docs/API.md) for complete reference.

## ğŸ³ Docker Deployment

### Quick Start

```bash
# Build and start
docker-compose up -d

# Or use helper scripts
./docker/start.sh  # Linux/Mac
docker\start.bat   # Windows
```

### Features

- âœ… MLflow integration (automatic Production model loading)
- âœ… Volume mounting for models and MLflow data
- âœ… Health checks included
- âœ… Production-ready configuration

### Commands

```bash
# Start
docker-compose up -d

# Stop
docker-compose down

# View logs
docker-compose logs -f

# Rebuild
docker-compose up -d --build
```

See [Docker Guide](docs/DOCKER.md) for detailed instructions.

## ğŸ“š Documentation

Comprehensive documentation is available in the `docs/` directory:

- **[Usage Guide](docs/USAGE.md)** - Complete usage instructions
- **[Training Guide](docs/TRAINING.md)** - Training workflows and best practices
- **[Model Registry Guide](docs/MODEL_REGISTRY.md)** - Model versioning system
- **[API Documentation](docs/API.md)** - Complete API reference with examples
- **[MLflow Guide](docs/MLFLOW_GUIDE.md)** - MLflow integration and workflows
- **[Docker Guide](docs/DOCKER.md)** - Docker deployment and management
- **[Deployment Guide](docs/DEPLOYMENT.md)** - Production deployment strategies
- **[CI/CD Guide](docs/CI_CD.md)** - Continuous Integration setup
- **[Testing Guide](docs/TESTING.md)** - Testing framework and practices

## ğŸ§ª Model Architectures

The project supports four deep learning architectures:

- **LSTM**: Standard Long Short-Term Memory network
- **BiLSTM**: Bidirectional LSTM for better context understanding
- **GRU**: Gated Recurrent Unit (faster training, similar performance)
- **Transformer**: Transformer encoder with attention mechanism

All models are configured with:
- Sequence length: 30 cycles
- Input features: 24 (3 operational settings + 21 sensors)
- Hidden size: 64
- Number of layers: 2
- Dropout: 0.2

## ğŸ”„ MLflow Workflow

### Training with MLflow

```bash
# Train all models and auto-promote best
python -m src.train_with_mlflow --epochs 20 --auto-promote
```

### View Experiments

```bash
mlflow ui
# Open http://localhost:5000
```

### Model Management

- **View Models**: MLflow UI â†’ Models
- **Promote to Production**: Add alias "production" to desired version
- **Compare Models**: Select multiple runs in MLflow UI

### API Integration

```bash
# API automatically uses Production model
USE_MLFLOW=true uvicorn src.api.main:app
```

See [MLflow Guide](docs/MLFLOW_GUIDE.md) for detailed information.

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_api.py -v
```

See [Testing Guide](docs/TESTING.md) for more information.

## ğŸ¤ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- CMAPSS dataset from NASA
- PyTorch for deep learning framework
- MLflow for MLOps capabilities
- FastAPI for API framework

## ğŸ“ Support

For issues, questions, or contributions:
- Open an issue on GitHub
- Check the [documentation](docs/)
- Review [FAQ](docs/USAGE.md#troubleshooting)

---

**Status**: âœ… Production-ready MLOps pipeline with MLflow integration
