# Python Scripts Conversion Summary

## âœ… What Was Created

The notebook `01_dataset_exploration.ipynb` has been successfully converted into a modular Python script structure:

### Core Modules

1. **`src/config.py`** - Centralized configuration
   - All hyperparameters (SEED, SEQ_LENGTH, BATCH_SIZE, EPOCHS, LR)
   - Paths (DATA_DIR, MODEL_DIR, file paths)
   - Model names and feature columns

2. **`src/utils.py`** - Utility functions
   - `set_seed()` - Reproducibility
   - `get_device()` - Device detection (CPU/CUDA)

3. **`src/data/load_data.py`** - Data loading
   - `load_train_data()` - Load training data
   - `load_test_data()` - Load test data
   - `load_rul_data()` - Load RUL labels

4. **`src/data/preprocessing.py`** - Data preprocessing
   - `calculate_rul()` - Compute RUL from cycles
   - `fit_scaler()` / `load_scaler()` - Scaler management
   - `scale_features()` - Feature scaling
   - `generate_sequences()` - Training sequence generation
   - `generate_test_sequences()` - Test sequence generation

5. **`src/models/architectures.py`** - Model definitions
   - `RUL_LSTM` - LSTM model
   - `RUL_BiLSTM` - Bidirectional LSTM
   - `RUL_GRU` - GRU model
   - `RUL_Transformer` - Transformer encoder
   - `get_model()` - Factory function

### Main Scripts

6. **`src/train.py`** - Training script
   ```bash
   python -m src.train --model lstm --epochs 20
   ```

7. **`src/evaluate.py`** - Evaluation script
   ```bash
   python -m src.evaluate --model lstm
   ```

8. **`src/predict.py`** - Prediction script
   ```bash
   python -m src.predict --model lstm --input data.csv
   ```

9. **`src/compare_models.py`** - Model comparison script
   ```bash
   python -m src.compare_models
   ```

## ğŸ“ Project Structure

```
predictive-maintenance-mlops/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ train.py              # Main training script
â”‚   â”œâ”€â”€ evaluate.py           # Main evaluation script
â”‚   â”œâ”€â”€ predict.py            # Main prediction script
â”‚   â”œâ”€â”€ compare_models.py     # Compare all models
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ architectures.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_dataset_exploration.ipynb  # Keep for visualization
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                  # Data files
â”œâ”€â”€ models/                   # Saved models & scalers
â”œâ”€â”€ USAGE.md                  # Detailed usage guide
â””â”€â”€ SCRIPTS_README.md         # This file
```

## ğŸ¯ Key Benefits

### âœ… Clean Separation of Concerns
- **Data loading** â†’ `src/data/load_data.py`
- **Preprocessing** â†’ `src/data/preprocessing.py`
- **Model definitions** â†’ `src/models/architectures.py`
- **Training logic** â†’ `src/train.py`
- **Evaluation logic** â†’ `src/evaluate.py`
- **Inference logic** â†’ `src/predict.py`

### âœ… Reusable Code
- Functions can be imported and reused
- Easy to extend with new models or preprocessing steps
- Configuration centralized in one place

### âœ… Production Ready
- Command-line interfaces for all scripts
- Proper error handling
- Reproducible (seeding, consistent paths)
- No data leakage (same logic as notebook)

### âœ… CI/CD Friendly
- Can be run in automated pipelines
- Easy to integrate with MLflow, DVC, etc.
- Scripts can be containerized

### âœ… Deployment Ready
- `predict.py` can be integrated into FastAPI/Flask
- Models and scalers are saved separately
- Clear input/output interfaces

## ğŸ“ Usage Examples

### Quick Start

```bash
# 1. Train a model
python -m src.train --model lstm

# 2. Evaluate the model
python -m src.evaluate --model lstm

# 3. Compare all models
python -m src.compare_models

# 4. Predict on new data
python -m src.predict --model lstm --input new_data.csv
```

### Advanced Usage

```bash
# Train with custom hyperparameters
python -m src.train --model lstm --epochs 30 --batch-size 128 --lr 0.0005

# Evaluate with custom model path
python -m src.evaluate --model lstm --model-path models/custom.pth

# Predict with custom output
python -m src.predict --model lstm --input data.csv --output results.csv
```

## ğŸ”„ Notebook vs Scripts

### Keep Notebook For:
- âœ… Data exploration and visualization
- âœ… Model comparison plots
- âœ… Experimentation and debugging
- âœ… Interactive analysis

### Use Scripts For:
- âœ… Production training pipelines
- âœ… Automated evaluation
- âœ… CI/CD integration
- âœ… Inference on new data
- âœ… Model deployment

## âœ¨ Features

- **No Data Leakage**: Same preprocessing logic as notebook
- **Reproducible**: Seeding and consistent paths
- **Modular**: Easy to extend and modify
- **Well Documented**: Docstrings and usage guides
- **Type Hints**: Better IDE support and error detection
- **Error Handling**: Proper file existence checks

## ğŸš€ Next Steps

1. **Train all models**:
   ```bash
   python -m src.train --model lstm
   python -m src.train --model bilstm
   python -m src.train --model gru
   python -m src.train --model transformer
   ```

2. **Compare models**:
   ```bash
   python -m src.compare_models
   ```

3. **Use for inference**:
   ```bash
   python -m src.predict --model lstm --input your_data.csv
   ```

4. **Integrate with MLflow** (optional):
   - Add MLflow tracking to `train.py`
   - Log metrics, parameters, and artifacts

5. **Create API** (optional):
   - Use `predict.py` logic in FastAPI endpoint
   - Serve models via REST API

## ğŸ“š Documentation

- See `USAGE.md` for detailed usage instructions
- See docstrings in each module for function documentation
- See `src/config.py` for all configuration options

